{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 8: More pandas, and visualising data with seaborn\n",
    "\n",
    "This week, we show further examples of how **pandas** can help us handle real-life data. We introduce the **seaborn** library, which provides useful tools for data visualisation, and works well with pandas dataframes.\n",
    "\n",
    "The best way to learn programming is to write code. Don't hesitate to edit the code in the example cells, or add your own code, to test your understanding. You will find practice exercises throughout the notebook, denoted by ðŸš© **Exercise $x$**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Dealing with real-world data using pandas\n",
    "\n",
    "We discussed some of the basics of working with Pandas last week. This week we should mention two more fundamentals for dealing with real-world data, namely dealing with **missing data**, and dealing with **text-based data**.\n",
    "\n",
    "### Missing data\n",
    "\n",
    "Firstly missing data. You will find the 3 datasets `tag00034-2.csv`, `wfhuk_1.1_dec2015.csv`, and `COSING_Ingredients-Fragrance Inventory_v2.csv` in your repository.\n",
    "\n",
    "The first of these is a European dataset on wine production from EU data [here](http://data.europa.eu/euodp/en/data/). This dataset has a number of missing values. Firstly notice what happens when you just read-in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "wine = pd.read_csv('tag00034-2.csv')\n",
    "wine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the missing values in the data (compare what the data looks like when you open it in Excel) are marked with the value `NaN`, which stands for 'Not a Number' -- we've seen it before as `np.nan`.\n",
    "\n",
    "This dataset is however inconsistent. Sometimes a missing value is just an empty cell - which Pandas handles correctly automatically, and sometimes the value is filled with a `:` character. This sort of thing often happens when data is collected (due to different people collecting data with different conventions, or someone inexpertly and inconsistently collecting data).\n",
    "\n",
    "If we print the contents of one of these cells, we can see that it's actually a colon and a space. We can make this uniform by replacing this value with the `NaN` value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(f'The string is \"{wine.loc[11, \"B2200,12HL,DK\"]}\".')\n",
    "\n",
    "# Replace all of the ':' values with NaN:\n",
    "wine = wine.replace(': ', np.nan)\n",
    "wine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the data is uniformly dealt with.\n",
    "\n",
    "Many functions ignore the `NaN` values when these are used in a calculation. However sometimes we want to clean up the data, and there are really two ways this might be done:\n",
    "- we could remove every row (or column) with `NaN` values in,\n",
    "- or we could proceed by replacing these `NaN` values with a particular numerical value.\n",
    "\n",
    "Here is how these two data cleaning operations might be done:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all the rows containing NaN\n",
    "wine.dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace all NaN with a given value\n",
    "wine.fillna(value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Dealing with text-based data\n",
    "\n",
    "Let's now consider how to deal with text-based data. Here is another dataset - this one is from a UK government dataset on waste from [here](https://data.gov.uk/dataset/uk_statistics_on_waste/). Here it is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waste = pd.read_csv('wfhuk_1.1_dec2015.csv')\n",
    "waste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we just wanted the 'Recycled' rows? We could find all of those rows where 'Recycled' occurs in the 'Measure' column using text methods, combined with `.loc[]` and boolean indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get every row with the condition that the string in\n",
    "# the 'Measure' column starts with 'Recycled'\n",
    "waste.loc[waste['Measure'].str.startswith('Recycled')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regular expression patterns\n",
    "\n",
    "Lastly, it is possible to do more complicated pattern matching - this uses a way of expressing text patterns called **Regular expressions**. This is a very large subject we could spend several weeks talking about - but I just want to make you aware of it as it is one of the central ways of matching patterns in textual data. There are some good links here:\n",
    "\n",
    "- The python module for regular expressions is detailed [here](https://docs.python.org/3/library/re.html)\n",
    "- Working with regular expressions in Pandas is detailed [here](http://pandas.pydata.org/pandas-docs/stable/text.html#testing-for-strings-that-match-or-contain-a-pattern) \n",
    "- [This is a good reference book](http://regex.info/book.html) on regular expressions if you find you have to use them\n",
    "\n",
    "Here is a quick example using pattern matching, with a longer and more complicated dataset - this is an EU dataset on [Fragrance ingredients](http://data.europa.eu/euodp/en/data/dataset/cosmetic-ingredient-database-ingredients-and-fragrance-inventory/resource/33aa4726-d05c-4756-ad91-6c6297de9771). The method allowing us to find the pattern is `str.match()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frag = pd.read_csv('COSING_Ingredients-Fragrance Inventory_v2.csv', encoding='utf')\n",
    "\n",
    "# This prints out lines where in the 'Chem/IUPAC Name / Description' column, there is\n",
    "# a match with the word 'Chamomil...' where the ending can be any number of the letters \n",
    "# l e or a:\n",
    "frag.loc[frag['Chem/IUPAC Name / Description'].str.match(r'Chamomil[lea]+')==True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**ðŸ“š Learn more:**\n",
    "\n",
    "- [Dealing with text data](http://pandas.pydata.org/pandas-docs/stable/text.html#testing-for-strings-that-match-or-contain-a-pattern) - pandas documentation\n",
    "- [pandas.DataFrame.fillna()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.fillna.html?highlight=fillna#pandas-dataframe-fillna)\n",
    "- [pandas.DataFrame.dropna()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dropna.html?highlight=dropna#pandas-dataframe-dropna)\n",
    "- [pandas.DataFrame.replace()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.replace.html?highlight=replace#pandas-dataframe-replace)\n",
    "- [Python regular expressions](https://docs.python.org/3/library/re.html)\n",
    "\n",
    "---\n",
    "\n",
    "**ðŸš© Exercise**\n",
    "- Make some plots of the data in the wine dataset `tag00034-2.csv`. Try with and without replacing the `NaN` values with some fill value (say zero). \n",
    "\n",
    "- Make some plots of the data in the `wfhuk_1.1_dec2015.csv` file that has 'Arisings' in the 'Measure' column.\n",
    "\n",
    "- Get the CAS No of every ingredient marked as being used for 'Skin Conditioning' in the `COSING_Ingredients-Fragrance Inventory_v2.csv` dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Seaborn for data visualisation\n",
    "\n",
    "seaborn is a library based on matplotlib, which provides very useful tools for various statistics and data visualisations. As for pandas, it wouldn't be reasonable to try and present all the functionality here -- luckily, the [documentation page](https://seaborn.pydata.org/) includes:\n",
    "\n",
    "- [a fantastic example gallery](https://seaborn.pydata.org/examples/index.html) demonstrating the types of visualisations you can do,\n",
    "- [an introduction with plenty of examples](https://seaborn.pydata.org/introduction.html),\n",
    "- [a tutorial/user guide](https://seaborn.pydata.org/tutorial.html).\n",
    "\n",
    "For example, the `catplot` function in seaborn ([documentation](https://seaborn.pydata.org/generated/seaborn.catplot.html#seaborn.catplot)) can create categorical subplots easily from pandas dataframes, to visualise the relations between different columns. Let's look at another dataset, listing all the astronauts which have ever been in space (up until 2020), and a lot of information about their different missions. The data was found [here](https://github.com/rfordatascience/tidytuesday/tree/master/data/2020/2020-07-14)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "astronauts = pd.read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-07-14/astronauts.csv')\n",
    "astronauts = astronauts.fillna('')\n",
    "astronauts.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's see the distribution of military and civilian astronauts who went to space every year, and whether they were male or female. (Unfortunately, it doesn't seem like there have been nonbinary astronauts in space yet!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot histograms using catplot\n",
    "grid = sns.catplot(data=astronauts,           # the dataframe\n",
    "                   x='year_of_mission',       # the x-axis (the bins)\n",
    "                   col='military_civilian',   # separate plots for each value in the column 'military_civilian'\n",
    "                   hue='sex',                 # different colours (hues) for male and female astronauts\n",
    "                   kind='count',              # the type of plot (countplot, or a histogram)\n",
    "                   legend=True,               # display the legend for the different colours\n",
    "                   col_wrap=1,                # start new row of subplots after just 1 plot\n",
    "                   height=3,                  # height of each plot\n",
    "                   aspect=3)                  # aspect ratio of each plot (width/height)\n",
    "\n",
    "# Rotate the tick labels so we can read them all\n",
    "grid.set_xticklabels(rotation=45,\n",
    "                     verticalalignment='top',\n",
    "                     horizontalalignment='right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spot Valentina Tereshkova, the first woman in space, in 1963 -- we wouldn't see another one until the 1980s!\n",
    "\n",
    "The history of space travel started with in the 1950s, with the \"space race\" between the USA and the USSR, and other countries started sending people into space quite a bit later. We would probably expect that most astronauts in this list are either American or Soviet -- we can check, using the `nunique()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of names whose nationality is USA, USSR, or other\n",
    "USA_count = astronauts.loc[astronauts['nationality'] == 'U.S.', 'name'].nunique()\n",
    "USSR_count = astronauts.loc[astronauts['nationality'].str.startswith('U.S.S.R'), 'name'].nunique()\n",
    "other_count = astronauts['name'].nunique() - USA_count - USSR_count\n",
    "\n",
    "print('American astronauts:', USA_count)\n",
    "print('Soviet cosmonauts:', USSR_count)\n",
    "print('All other countries:', other_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Astronauts have used different shuttles to go to the Mir station or the International Space Station (ISS) -- if you look at the data, you'll see that this is mainly `STS` (the American Space Shuttle) or `Soyuz` (the Russian spacecraft)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"|\" here means \"or\", but works on whole dataframes\n",
    "rows = (astronauts['in_orbit'] == 'Mir') | (astronauts['in_orbit'] == 'ISS')\n",
    "columns = ['year_of_mission', 'ascend_shuttle', 'in_orbit', 'hours_mission']\n",
    "station_trips = astronauts.loc[rows, columns]\n",
    "\n",
    "# Rename labels to group them together as either \"Soyuz\" or \"Space Shuttle\"\n",
    "station_trips.loc[station_trips['ascend_shuttle'].str.contains('soyuz', case=False), 'ascend_shuttle'] = 'Soyuz'\n",
    "station_trips.loc[station_trips['ascend_shuttle'].str.contains('sts', case=False), 'ascend_shuttle'] = 'Space Shuttle'\n",
    "\n",
    "# Here, we use relplot() (relational plot) to make a scatter plot.\n",
    "# Try to figure out what each parameter corresponds to!\n",
    "grid = sns.relplot(data=station_trips,\n",
    "                   x='year_of_mission',\n",
    "                   y='hours_mission',\n",
    "                   hue='ascend_shuttle',\n",
    "                   style='in_orbit',\n",
    "                   height=4,\n",
    "                   aspect=2)\n",
    "\n",
    "# Set the x-axis ticks and labels to show the year of mission for each trip\n",
    "grid.set(xticks=station_trips['year_of_mission'].unique())\n",
    "grid.set_xticklabels(rotation=45,\n",
    "                     verticalalignment='top',\n",
    "                     horizontalalignment='right',\n",
    "                     labels=station_trips['year_of_mission'].unique())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that:\n",
    "\n",
    "- Most missions on the space stations seem to last around 4000 hours (around 6 months), although 2 astronauts have stayed on a space station for over 10,000 hours (more than a year!).\n",
    "- The Space Shuttle (orange) brought a few astronauts to Mir until it was deorbited in 2001, and then continued to bring astronauts to the ISS until the Shuttle program was discontinued.\n",
    "- Soyuz seems to have been the only way to bring people to the ISS since 2010!\n",
    "- Mir and the ISS briefly coexisted in the year 2000.\n",
    "\n",
    "---\n",
    "**ðŸ“š Learn more:**\n",
    "\n",
    "- [Visualising statistical relationships](https://seaborn.pydata.org/tutorial/relational.html#visualizing-statistical-relationships) - Seaborn tutorial\n",
    "- [Building structured multi-plot grids](https://seaborn.pydata.org/tutorial/axis_grids.html) - Seaborn tutorial\n",
    "- [Plotting with categorical data](https://seaborn.pydata.org/tutorial/categorical.html#categorical-tutorial) - Seaborn tutorial\n",
    "\n",
    "---\n",
    "**ðŸš© Exercise** There really is a huge amount of functionality with using seaborn to visualise data in pandas dataframes -- covering everything in this tutorial sheet would be impossible. A great way to figure it out is to practice and tinker with it. Start from this dataset and the graph above, and change some of the parameters to display different things; then, try to find out more interesting things about the astronauts. Here are a few examples to get you started:\n",
    "\n",
    "- Change the code above to display the sex of the astronauts in 2 different colours, instead of the ascend shuttle.\n",
    "- Change 'hours_mission' to 'age' above to plot the age of astronauts going to Mir or the ISS over the years.\n",
    "- What is the average duration of a mission to Mir? to the ISS?\n",
    "- How long was the longest mission, in days? Who was the astronaut?\n",
    "- Which countries have sent civilians to space?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Grouping and reshaping dataframes\n",
    "\n",
    "When analysing data, it is often useful to aggregate it along a certain variable. A commonly used workflow to do this is often referred to as **split-apply-combine** -- here is a handy diagram to summarise an example, found in [VanDerPlas' *The Python Data Science Handbook*](https://jakevdp.github.io/PythonDataScienceHandbook/03.08-aggregation-and-grouping.html#GroupBy:-Split,-Apply,-Combine) (in your reading list):\n",
    "\n",
    "![Split-apply-combine](https://jakevdp.github.io/PythonDataScienceHandbook/figures/03.08-split-apply-combine.png)\n",
    "\n",
    "- First, we **split** our data into several **groups**, using the different values found in a given column.\n",
    "- Then, we **apply** a particular operation to aggregate the data in each group.\n",
    "- Finally, we **combine** the aggregated data together in a new dataframe.\n",
    "\n",
    "Pandas offers the `.groupby()` method to do this.\n",
    "\n",
    "For instance, going back to the example from earlier, we used logical indexing to find the number of astronauts in the database which where American, Soviet, or from any other country. We can use `.groupby()` to do this more concisely -- and without singling out any particular country. Let's start by grouping the data by nationality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the dataframe by nationality\n",
    "astronauts.groupby('nationality')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We obtain a `DataFrameGroupBy object` -- so far that's not very useful. This is essentially a group of smaller dataframes -- we are at the first step (\"Split\") of the diagram above.\n",
    "\n",
    "We can look at the [documentation for `GroupBy` objects](https://pandas.pydata.org/docs/reference/groupby.html), which gives us all the different functions and methods we can use with this kind of object.\n",
    "\n",
    "For example, let's look at one of the groups, using `.get_group()` to show a dataframe of the Japanese astronauts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the British astronauts only\n",
    "astronauts.groupby('nationality').get_group('Japan')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we could also do the same thing with logical indexing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "astronauts.loc[astronauts['nationality'] == 'Japan']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, the advantage of using `.groupby()` is that we have all these convenient functions available to perform some computations on *all* the different groups, instead of having to choose one (or loop manually over each possible nationality). For example: how many astronauts are from each different country?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of unique astronauts in each country\n",
    "astronauts.groupby('nationality')['name'].nunique().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To summarise the command:\n",
    "\n",
    "- `astronauts.groupby('nationality')` creates the `DataFrameGroupBy` object, i.e. **splits** the dataframe into multiple groups according to nationality.\n",
    "- `['name']` extracts the `name` column in each group, to get the name of each astronaut.\n",
    "- `.nunique()` **applies** an aggregating function to each group -- in this case, count the number of unique names.\n",
    "- `.sort_values(ascending=False)` sorts the results in descending order.\n",
    "\n",
    "---\n",
    "**ðŸš© Exercise**\n",
    "\n",
    "Have fun with some data! Explore the examples gallery in the seaborn documentation, the different functions of the pandas documentation, and make some visualisations that you find interesting. You could even use SciPy or Numpy to perform more complex operations.\n",
    "\n",
    "You can use these datasets, or find other ones -- here are a few places you could start looking:\n",
    "- [The `tidytuesday` repo](https://github.com/rfordatascience/tidytuesday)\n",
    "- A curated list of [awesome public datasets](https://github.com/awesomedata/awesome-public-datasets)\n",
    "- [Kaggle](https://www.kaggle.com/datasets) has lots of public datasets (make sure you filter by CSV files)\n",
    "- [Edinburgh Council](https://edinburghopendata.info/) releases some data to the public\n",
    "- [The Scottish government](https://statistics.gov.scot/home), [the British government](https://data.gov.uk/), and [the EU](https://data.europa.eu/euodp/en/data/) also release data\n",
    "- The [Harvard dataverse](https://dataverse.harvard.edu/), more skewed towards research data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
